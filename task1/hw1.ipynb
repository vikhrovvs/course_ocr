{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d269a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from course_ocr_t1.data import MidvPackage\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e639c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from  torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a2c3dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b5305a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = Path() / '..'/ '..' / 'data' / 'midv500_compressed'\n",
    "assert DATASET_PATH.exists(), DATASET_PATH.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f99933c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, course_ocr_t1.data.MidvPackage)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_packs = MidvPackage.read_midv500_dataset(DATASET_PATH)\n",
    "len(data_packs), type(data_packs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b1e0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac0a82df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class task1_dataset(Dataset):\n",
    "    def __init__(self, data_packs, device, split = 'train'):\n",
    "        assert split in ['train', 'test']\n",
    "        self.data_packs = data_packs\n",
    "        self.indices = []\n",
    "        self.device = device\n",
    "        \n",
    "        if split == 'train':\n",
    "            for i, data_pack in enumerate(data_packs):\n",
    "                for j in range(len(data_pack)):\n",
    "                    if not data_pack[j].is_test_split():\n",
    "                        self.indices.append((i, j))\n",
    "        else:\n",
    "            for i, data_pack in enumerate(data_packs):\n",
    "                for j in range(len(data_pack)):\n",
    "                    if data_pack[j].is_test_split():\n",
    "                        self.indices.append((i, j))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        i, j = self.indices[idx]\n",
    "        dp = self.data_packs[i][j]\n",
    "        image = np.array(dp.image.convert('RGB')) / 255.\n",
    "        mask = cv2.fillConvexPoly(np.zeros(image.shape[:2]), np.array(dp.gt_data['quad']), (1,))[np.newaxis, ...]\n",
    "        return torch.tensor(image.transpose(2, 0, 1), dtype=torch.float, deivce=device),\n",
    "                torch.tensor(mask, dtype=torch.float, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e625e011",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = task1_dataset(data_packs, 'train') # TODO: transform\n",
    "val_data = task1_dataset(data_packs, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "730009e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=4\n",
    "train_dl = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(val_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fef0028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class enc_conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e3c4d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class upsample_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.upsample = nn.Upsample(scale_factor=2)\n",
    "        self.dec_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, u, e):\n",
    "        u = self.upsample(u)\n",
    "        pad_w = e.shape[2] - u.shape[2]\n",
    "        pad_h = e.shape[3] - u.shape[3]\n",
    "        padding = [pad_h // 2, pad_h - pad_h // 2, pad_w // 2, pad_w - pad_w // 2]\n",
    "#         print(e.shape, u.shape)\n",
    "#         print(padding)\n",
    "        u = nn.functional.pad(u, padding)\n",
    "        return self.dec_conv(torch.cat((e, u), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a663244",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        # encoder\n",
    "        self.enc_conv0 = enc_conv_block(3, 64)\n",
    "        self.pool0 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc_conv1 = enc_conv_block(64, 128)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc_conv2 = enc_conv_block(128, 256)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.enc_conv3 = enc_conv_block(256, 512)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # bottleneck\n",
    "        self.bottleneck_conv = enc_conv_block(512, 1024)\n",
    "\n",
    "        # decode\n",
    "        self.up_0 = upsample_block(1024+512, 512)\n",
    "        self.up_1 = upsample_block(512+256, 256)\n",
    "        self.up_2 = upsample_block(256+128, 128)\n",
    "        self.up_3 = upsample_block(128+64, 64)\n",
    "        \n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        e0 = self.enc_conv0(x)\n",
    "        e1 = self.enc_conv1(self.pool0(e0))\n",
    "        e2 = self.enc_conv2(self.pool1(e1))\n",
    "        e3 = self.enc_conv3(self.pool2(e2))\n",
    "\n",
    "        # bottleneck\n",
    "        b = self.bottleneck_conv(self.pool3(e3)) \n",
    "\n",
    "        # decoder\n",
    "        u0 = self.up_0(b, e3)\n",
    "        u1 = self.up_1(u0, e2)\n",
    "        u2 = self.up_2(u1, e1)\n",
    "        u3 = self.up_3(u2, e0)\n",
    "        \n",
    "        out = self.out(u3)\n",
    "        return out\n",
    "unet_model = UNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2984ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c547fc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, loss_fn, epochs, data_tr, data_val):\n",
    "    X_val, Y_val = next(iter(data_val))\n",
    "    train_loss, val_loss, val_score = [], [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        tic = time()\n",
    "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
    "\n",
    "        avg_loss = 0\n",
    "        model.train()\n",
    "        for X_batch, Y_batch in tqdm(data_tr):\n",
    "#             X_batch = X_batch.to(device)\n",
    "#             Y_batch = Y_batch.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "            Y_pred = model(X_batch)\n",
    "            \n",
    "            loss = loss_fn(Y_batch, Y_pred)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            avg_loss += loss / len(data_tr)\n",
    "        toc = time()\n",
    "        print('loss: %f' % avg_loss)\n",
    "        train_loss.append(avg_loss)\n",
    "        \n",
    "        model.eval()\n",
    "        Y_hat = model(X_val.to(device)).detach().cpu()\n",
    "\n",
    "        val_loss_sum = 0\n",
    "        val_score_sum = 0\n",
    "        for X_val_batch, Y_val_batch in data_val:\n",
    "            X_val_batch = X_val_batch.to(device)\n",
    "            Y_val_batch = Y_val_batch.to(device)\n",
    "            with torch.set_grad_enabled(False):\n",
    "                Y_pred_batch = model(X_val_batch)\n",
    "                loss = loss_fn(Y_val_batch, Y_pred_batch)\n",
    "                prediction = torch.sigmoid(Y_pred_batch) > 0.5\n",
    "            val_loss_sum += loss\n",
    "            val_score_sum += iou_pytorch(prediction, Y_val_batch).mean().item()\n",
    "        processed_size = len(data_val)\n",
    "        val_loss.append(val_loss_sum/processed_size)\n",
    "        val_score.append(val_score_sum/processed_size)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize = (16, 7))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title('Loss')\n",
    "        plt.plot(train_loss, label='train loss')\n",
    "        plt.plot(val_loss, label='val loss')\n",
    "        plt.legend()\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title('Score')\n",
    "        plt.plot(val_score)\n",
    "        plt.show()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        for k in range(6):\n",
    "            plt.subplot(2, 6, k+1)\n",
    "            plt.imshow(np.rollaxis(X_val[k].numpy(), 0, 3), cmap='gray')\n",
    "            plt.title('Real')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(2, 6, k+7)\n",
    "            plt.imshow(Y_hat[k, 0], cmap='gray')\n",
    "            plt.title('Output')\n",
    "            plt.axis('off')\n",
    "        plt.suptitle('%d / %d - loss: %f' % (epoch+1, epochs, avg_loss))\n",
    "        plt.show()\n",
    "\n",
    "    return train_loss, val_loss, val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0b8df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "unet_train_loss, unet_val_loss, unet_val_score = train(unet_model, torch.optim.Adam(unet_model.parameters()), nn.BCELoss(), 100, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a643641e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
